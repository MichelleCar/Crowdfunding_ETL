# Extract, transform, and load (ETL) - A Crowdfunding Case Study
![ezgif com-gif-maker--1-](https://user-images.githubusercontent.com/115101031/214898164-a525647c-e9d6-40db-9956-c4694b86b66b.png)

## What is ETL?
ETL is a type of data integration that refers to the three steps (extract, transform, load) used to blend data from multiple sources. It's often used to build a data warehouse. During this process, data is taken (extracted) from a source system, converted (transformed) into a format that can be analyzed, and stored (loaded) into a data warehouse or other system. 

![etl-process-explained-diagram](https://user-images.githubusercontent.com/115101031/214889820-09a11cb8-f4d2-4b5b-a33a-c2952d8b2ad3.png)

#### Key reasons for using ETL are:
* Visualizing your entire data flow pipeline which helps making decisions.
* Transactional databases cannot answer all the questions that can be answered by ETL.
* ETL provides a method of moving the data from various sources into a comprehensive data warehouse.
* As data sources change, the Data Warehouse will automatically update.
* ETL process can perform complex transformations and requires the extra area to store the data.
* ETL helps to Migrate data into a Data Warehouse. Convert to the various formats and types to adhere to one consistent system.
* ETL is a predefined process for accessing and manipulating source data into the target database.
* By providing a consolidated view, ETL makes it easier for users to analyze and report on data relevant to their initiatives.
* Users can combine legacy data with data from new platforms and applications. You can view older datasets alongside more recent information, which gives you a long-term view of data.



Sources:
* https://medium.datadriveninvestor.com/understanding-extract-transform-and-load-etl-and-its-necessity-in-data-analytics-world-with-an-64346016153d
* https://www.sas.com/en_ca/insights/data-management/what-is-etl.html#etl-importance
* https://aws.amazon.com/what-is/etl/ 


ETL project: 1) build ETL pipeline, 3) Create CSV files and create ERD and table schema, 4) Upload CSV file data into Postgres database

